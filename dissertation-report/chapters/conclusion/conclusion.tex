\chapter{Conclusion\label{chap:conclusion}}
\section{Summary}
This dissertation aimed to evaluate and statistically compare the performance of three counterfactual explanation generation frameworks, DiCE and AIDE, with an additional evaluation of DiCE's genetic variant based on GeCo. The study addressed the research questions of whether AIDE, an immune-inspired algorithm, is well-suited for counterfactual generation compared to DiCE and DiCE-genetic. To achieve this, a comprehensive experiment was conducted, employing both quantitative evaluation using established metrics (Size, Dissimilarity, Actionability, Diversity, and Runtime) and qualitative analysis through parallel coordinates plots across four benchmark tabular datasets.

The quantitative results revealed that both AIDE and DiCE generally achieved the requested size of counterfactuals, while DiCE-genetic struggled to consistently do so. In terms of the key metrics in the literature, DiCE demonstrated the best proximity to the original instance (lowest dissimilarity distance), with statistically significant differences compared to AIDE and DiCE-genetic. On the other hand, AIDE exhibited higher diversity in both distance and count, significantly outperforming the other methods in diversity count. The difference in means for the distances shows that AIDE possibly handles the trade-off better than the other methods. AIDE showed a tendency for higher actionability, although this was not statistically significant overall. Regarding computational efficiency, DiCE-genetic had the fastest runtime, followed by DiCE, while AIDE was significantly slower due to the experimental setup involving a higher iteration limit and a single-shot generation approach.

The qualitative analysis using parallel coordinates plots provided valuable insights into how each method alters features to generate counterfactuals. These visualizations suggested that the methods handle continuous and categorical features differently, highlighting potential limitations in how each framework explores the feature space and adheres to the underlying data distribution. For example, DiCE sometimes generated counterfactuals in low-density regions of the data, and struggled with changing categorical features in the adult dataset. AIDE generally performed well with categorical features but occasionally produced unrealistic combinations.

Overall, the findings suggest that no single method is definitively superior across all evaluation metrics. This agrees with work by \citet{guidotti2024counterfactual}. While AIDE performed well in terms of diversity and showed promise in actionability, it suffered from longer runtimes and higher dissimilarity distances compared to DiCE in some cases. DiCE excelled in generating proximal counterfactuals but sometimes lacked diversity and struggled with categorical features. DiCE-genetic offered faster runtimes but had issues with consistently generating the required number of valid counterfactuals. Therefore due to the high variance across all of the datasets, the choice of the most suitable counterfactual explanation method depends on the specific application and the dataset. When building a counterfactual-based XAI system, the three methods or maybe even more could be used to generate CFs. As it is already known by \citet{miller2019explanation} good explanations are also selective. So the next step would be to figure out the relative importance of different evaluation criteria for an end user.

\section{Future Work}
This work points towards several areas for future investigation. First of all, concerning the metrics. Other metrics like Instability, Implausibility, and Discriminative Power in section \ref{subsection:metrics} can be measured among DiCE, DiCE-genetic and AIDE. Another important check can be done by measuring the metrics separately for categorical and continuous features. Perhaps some explainers handle this better than others since it is a challenging task to quantify the amount of "difficulty" to change a categorical value to another one. Moreover, the proposed "Alignment" metric could be evaluated among all of the methods discussed in \citet{guidotti2024counterfactual}.

AIDE can be further improved by exploring adaptive strategies for hyperparameter tuning in AIDE, particularly the affinity constant. This could potentially a greater optimization to the trade-off between Diversity and Disimilarity, and possibly reduce the runtime. AIDE could also be adapted to hybrid approach and have diversity baked into the method. It could optimize equation \ref{eq:dice-loss} and the term $dpp\_diversity$ could prove to be very advantageous to find counterfactuals.

Extending the benchmarking to a wider range of datasets, including those with different characteristics (e.g., higher dimensionality, imbalanced classes), would provide a more robust comparison of the methods' generalizability. Perhaps a comparison between domains/datasets could be done to see if counterfactuals perform better in some domains/datasets than others.

There is a lack of user studies to evaluate the discriminative power and "loveliness" of the counterfactual explanations. Experiments similar to \citet{forrest2021contrastive} can be done to include DiCE-genetic to provide crucial insights into their practical utility and user satisfaction.


To conclude, this comparative analysis not only reaffirms the complexity of generating truly effective counterfactual explanations, a significant challenge of making inherently opaque 'black box' models understandable, but also highlights the nuanced trade-offs between key properties like diversity and proximity. While no single method emerged as universally superior, the insights about the distinct behaviors of explainers on different feature types and the introduction of the Alignment metric direct the way for future hybrid approaches and user-centered evaluations. These advancements are essential for advancing the frontier of XAI toward systems that are not just interpretable, but genuinely trustworthy and beneficial in critical and socially sensitive decision-making contexts.
% Seperate Categorical and Continuous Features
% Suggest new algorithim - AIDE with DPP
%\begin{enumerate}
%\item Measure metrics like Instability, Implausibility, and Discriminative Power.
%\item Develop a version of AIDE that is optimized for a certain metric.
%\item Compare counterfactuals from different domains to check if counterfactuals perform better in some domains than others.
%\item Compare counterfactuals from different Black Box Models to see if counterfactuals perform better in specific models.
%\end{enumerate}